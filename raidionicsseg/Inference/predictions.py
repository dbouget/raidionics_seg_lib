import logging
import traceback
from copy import deepcopy
from math import ceil
from typing import List

import numpy as np
import onnxruntime as rt
from tqdm import tqdm

from ..Inference.data_augmentation import generate_augmentations
from ..Inference.data_augmentation import run_augmentations
from ..Utils.configuration_parser import ConfigResources
from ..Utils.volume_utilities import padding_for_inference
from ..Utils.volume_utilities import padding_for_inference_both_ends
from ..Utils.volume_utilities import padding_for_inference_both_ends_patchwise


def run_predictions(data: np.ndarray, models_path: List[str], parameters: ConfigResources) -> np.ndarray:
    """
    Performs inference using the specified model and TensorFlow as inference engine.

    Parameters
    ----------
    data : np.ndarray
        Pre-processed patient MRI, ready to be used by the inference engine.
    models_path : List[str]
        Filepath where the trained models are stored.
    parameters :  :obj:`ConfigResources`
        Loaded configuration specifying runtime parameters.
    Returns
    -------
    np.ndarray
        Predictions generated by the inference process.
    """
    providers = ["CPUExecutionProvider"]
    if parameters.gpu_id != "-1":
        providers = ["CUDAExecutionProvider"]
    model_outputs = []

    before_ensemble_results = []

    logging.debug("Predicting...")
    for f, mpf in enumerate(models_path):
        logging.debug("Loading trained model for fold {}".format(f))
        model = rt.InferenceSession(mpf, providers=providers)

        if parameters.new_axial_size and len(parameters.new_axial_size) == 3:
            final_result = __run_predictions_whole(
                data=data, model=model, parameters=parameters, deep_supervision=parameters.training_deep_supervision
            )
        elif parameters.new_axial_size and len(parameters.new_axial_size) == 2:
            final_result = __run_predictions_slabbed(
                data=data,
                model=model,
                model_outputs=model_outputs,
                parameters=parameters,
                deep_supervision=parameters.training_deep_supervision,
            )
        else:
            final_result = __run_predictions_patch(
                data=data, model=model, parameters=parameters, deep_supervision=parameters.training_deep_supervision
            )

        if parameters.predictions_test_time_augmentation_iterations > 0:
            logging.debug(
                "Running {} test time augmentation".format(parameters.predictions_test_time_augmentation_iterations)
            )
            augmented_results = np.zeros(
                final_result.shape + (parameters.predictions_test_time_augmentation_iterations + 1,),
                dtype=final_result.dtype,
            )
            augmented_results[..., 0] = final_result
            for i in tqdm(range(parameters.predictions_test_time_augmentation_iterations)):
                aug_list = generate_augmentations(modality=parameters.imaging_modality)
                data_aug = run_augmentations(aug_list, data, "forward")
                aug_result = None
                if parameters.new_axial_size and len(parameters.new_axial_size) == 3:
                    aug_result = __run_predictions_whole(
                        data=data_aug,
                        model=model,
                        parameters=parameters,
                        deep_supervision=parameters.training_deep_supervision,
                    )
                elif parameters.new_axial_size and len(parameters.new_axial_size) == 2:
                    aug_result = __run_predictions_slabbed(
                        data=data_aug,
                        model=model,
                        model_outputs=model_outputs,
                        parameters=parameters,
                        deep_supervision=parameters.training_deep_supervision,
                    )
                else:
                    aug_result = __run_predictions_patch(
                        data=data_aug,
                        model=model,
                        parameters=parameters,
                        deep_supervision=parameters.training_deep_supervision,
                    )
                augmented_results[..., i + 1] = np.clip(
                    run_augmentations(aug_list, aug_result, "inverse"), a_min=0.0, a_max=1.0
                )
            # Fusing all test time augmentation results with the main results
            if parameters.predictions_test_time_augmentation_fusion_mode == "maximum":
                final_result = np.amax(augmented_results, axis=-1).astype("float32")
            elif parameters.predictions_test_time_augmentation_fusion_mode == "average":
                final_result = np.average(augmented_results, axis=-1).astype("float32")
        before_ensemble_results.append(final_result)
        del model
    if not parameters.predictions_folds_ensembling:
        return before_ensemble_results[0]
    else:
        ens_result = None
        if parameters.predictions_ensembling_strategy == "maximum":
            ens_result = np.amax(np.stack(before_ensemble_results, axis=-1), axis=-1).astype("float32")
        elif parameters.predictions_ensembling_strategy == "average":
            ens_result = np.average(np.stack(before_ensemble_results, axis=-1), axis=-1).astype("float32")
        return ens_result


def __run_predictions_whole(
    data: np.ndarray, model, parameters: ConfigResources, deep_supervision: bool = False
) -> np.ndarray:
    """
    Performs inference using the specified model using the whole input at once.

    Parameters
    ----------
    data : np.ndarray
        Pre-processed patient MRI, ready to be used by the inference engine.
    model : obj
        Loaded ONNX model.
    parameters: ConfigResources
        Configuration parameters regarding model training or user choices.
    deep_supervision : bool
        Boolean flag to indicate if deep supervision is used in the model.
    Returns
    -------
    np.ndarray
        Predictions generated by the inference process.
    """
    try:
        logging.debug("Starting inference in full volume mode.")
        if parameters.preprocessing_channels_order == "channels_first":
            data = np.transpose(data, axes=(0, 4, 1, 2, 3))
        if parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_first":
            data = np.transpose(data, axes=(0, 1, 4, 2, 3))
        elif parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_last":
            data = np.transpose(data, axes=(0, 3, 1, 2, 4))

        predictions = model.run(None, {"input": data})
        if deep_supervision or parameters.training_backend == "Torch":
            predictions = predictions[0]

        if parameters.preprocessing_channels_order == "channels_first":
            predictions = np.transpose(predictions, axes=(0, 2, 3, 4, 1))
        if parameters.swap_training_input:
            predictions = np.transpose(predictions, axes=(0, 2, 3, 1, 4))

        # For PyTorch-trained models, the final activation layer is often not bundled with the model
        if not parameters.training_activation_layer_included:
            from ..Utils.volume_utilities import final_activation

            predictions = final_activation(predictions, act_type=parameters.training_activation_layer_type)

    except Exception as e:
        logging.error(f"Following error collected during model inference (whole mode): \n {e}")
        raise ValueError("Segmentation inference (whole mode) could not fully proceed.")

    # The batch size dimension can be removed at this point.
    return predictions[0]


def __run_predictions_slabbed(
    data: np.ndarray, model, model_outputs: List[str], parameters: ConfigResources, deep_supervision: bool = False
) -> np.ndarray:
    """

    @OBS. Not tested for PyTorch, but will most likely never be a use-case now that the patch-wise method is
     stable.
    """
    try:
        logging.debug("Starting inference in slab-wise mode.")
        slicing_plane = parameters.slicing_plane
        slab_size = parameters.training_slab_size
        new_axial_size = parameters.new_axial_size
        batch_size = parameters.inference_batch_size
        if parameters.swap_training_input:
            tmp = deepcopy(new_axial_size)
            new_axial_size[0] = tmp[1]
            new_axial_size[1] = tmp[0]

        upper_boundary = data.shape[3]
        if slicing_plane == "sagittal":
            upper_boundary = data.shape[1]
        elif slicing_plane == "coronal":
            upper_boundary = data.shape[2]

        # Placeholder for the final predictions -- the actual probabilities
        final_result = np.zeros(data.shape[1:-1] + (parameters.training_nb_classes,))
        count = 0
        overlapping_factor = slab_size
        if parameters.predictions_overlapping_ratio is not None:
            overlapping_factor = int(slab_size - (parameters.predictions_overlapping_ratio * slab_size))

        data, extra_dims = padding_for_inference(data=data, slab_size=slab_size, slicing_plane=slicing_plane)
        all_slabs_boundaries = []
        for i in range(ceil(upper_boundary / overlapping_factor)):
            slab_boundaries_x = []
            slab_boundaries_y = []
            slab_boundaries_z = []

            if slicing_plane == "axial":
                slab_boundaries_x = [0, data.shape[1]]
                slab_boundaries_y = [0, data.shape[2]]
                slab_boundaries_z = [int(i*overlapping_factor), min(data.shape[3], int(i*overlapping_factor) + slab_size)]
            elif slicing_plane == "sagittal":
                slab_boundaries_x = [int(i*overlapping_factor), min(data.shape[1], int(i*overlapping_factor) + slab_size)]
                slab_boundaries_y = [0, data.shape[2]]
                slab_boundaries_z = [0, data.shape[3]]
            elif slicing_plane == "coronal":
                slab_boundaries_x = [0, data.shape[1]]
                slab_boundaries_y = [int(i*overlapping_factor), min(data.shape[2], int(i*overlapping_factor) + slab_size)]
                slab_boundaries_z = [0, data.shape[3]]

            all_slabs_boundaries.append([slab_boundaries_x, slab_boundaries_y, slab_boundaries_z])

        for bs_ind in tqdm(range(ceil(len(all_slabs_boundaries) / batch_size))):
            batch_inputs = []
            slab_boundaries = all_slabs_boundaries[
                bs_ind * batch_size: min(len(all_slabs_boundaries), (bs_ind + 1) * batch_size)]
            for sb in slab_boundaries:
                slab_boundaries_x = sb[0]
                slab_boundaries_y = sb[1]
                slab_boundaries_z = sb[2]
                slab_arr = data[0, slab_boundaries_x[0]: slab_boundaries_x[1],
                slab_boundaries_y[0]: slab_boundaries_y[1], slab_boundaries_z[0]: slab_boundaries_z[1], :,]
                if slicing_plane == "sagittal":
                    slab_arr = slab_arr.transpose((1, 2, 0, 3))
                elif slicing_plane == "coronal":
                    slab_arr = slab_arr.transpose((0, 2, 1, 3))
                batch_inputs.append(slab_arr)
            model_input = np.stack(batch_inputs, axis=0)

            if parameters.fix_orientation:
                model_input = np.transpose(model_input, axes=(0, 3, 1, 2, 4))

            if parameters.preprocessing_channels_order == "channels_first":
                model_input = np.transpose(model_input, axes=(0, 4, 1, 2, 3))
            if parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_first":
                model_input = np.transpose(model_input, axes=(0, 1, 4, 2, 3))
            elif parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_last":
                model_input = np.transpose(model_input, axes=(0, 3, 1, 2, 4))
            # model_input = np.expand_dims(patch, axis=0)
            slab_pred = model.run(None, {"input": model_input})
            # @TODO. Have to test with a non deep supervision model with ONNX, to do array indexing always
            # if deep_supervision or parameters.training_backend == "Torch":
            slab_pred = slab_pred[0]

            if parameters.preprocessing_channels_order == "channels_first":
                slab_pred = np.transpose(slab_pred, axes=(0, 2, 3, 4, 1))
            if parameters.swap_training_input:
                slab_pred = np.transpose(slab_pred, axes=(0, 2, 3, 1, 4))
            if parameters.fix_orientation:
                slab_pred = np.transpose(slab_pred, axes=(0, 2, 3, 1, 4))

            # In case of overlapping inference, taking the maximum probabilities overall.
            for pbi, pb in enumerate(slab_boundaries):
                slab_pred_arr = slab_pred[pbi]
                if slicing_plane == "sagittal":
                    slab_pred_arr = slab_pred_arr.transpose((2, 0, 1, 3))
                elif slicing_plane == "coronal":
                    slab_pred_arr = slab_pred_arr.transpose((0, 2, 1, 3))
                slab_boundaries_x = pb[0]
                slab_boundaries_y = pb[1]
                slab_boundaries_z = pb[2]
                final_result[
                    slab_boundaries_x[0]: slab_boundaries_x[1],
                    slab_boundaries_y[0]: slab_boundaries_y[1],
                    slab_boundaries_z[0]: slab_boundaries_z[1],
                    :,
                ] = np.maximum(slab_pred_arr,
                    final_result[
                        slab_boundaries_x[0]: slab_boundaries_x[1],
                        slab_boundaries_y[0]: slab_boundaries_y[1],
                        slab_boundaries_z[0]: slab_boundaries_z[1],
                        :,
                    ],
                )
        final_result = final_result[
            extra_dims[0] : final_result.shape[0] - extra_dims[1],
            extra_dims[2] : final_result.shape[1] - extra_dims[3],
            extra_dims[4] : final_result.shape[2] - extra_dims[5],
            :,
        ]
    except Exception as e:
        logging.error(f"Following error collected during model inference (slab mode): \n {e}")
        raise ValueError("Segmentation inference (slab mode) could not fully proceed.")
    return final_result


def __run_predictions_patch(
    data: np.ndarray, model, parameters: ConfigResources, deep_supervision: bool = False
) -> np.ndarray:
    try:
        batch_size = parameters.inference_batch_size
        patch_size = parameters.training_patch_size if parameters.training_patch_size is not None else parameters.new_axial_size + [parameters.training_slab_size]
        patch_offset = parameters.training_patch_offset if parameters.training_patch_offset is not None else [0] * len(patch_size)
        logging.debug(f"Starting inference in patch-wise mode with batch-size {batch_size}.")

        if parameters.predictions_overlapping_ratio is not None:
            patch_offset = [int(parameters.predictions_overlapping_ratio * x) for x in patch_size]

        # Padding in case the patch size is larger that one of the volume dimensions
        data, extra_dims = padding_for_inference_both_ends_patchwise(data, patch_size)

        # Placeholder for the final predictions -- the actual probabilities
        final_result = np.full(data.shape[1:-1] + (parameters.training_nb_classes,), -100.0, dtype=np.float32)

        all_patch_boundaries = []
        for x in range(0, int(np.ceil(data.shape[1] / (patch_size[0] - patch_offset[0])))):
            for y in range(0, int(np.ceil(data.shape[2] / (patch_size[1] - patch_offset[1])))):
                for z in range(0, int(np.ceil(data.shape[3] / (patch_size[2] - patch_offset[2])))):
                    patch_boundaries_x = [
                        x * (patch_size[0] - patch_offset[0]),
                        x * (patch_size[0] - patch_offset[0]) + patch_size[0],
                    ]
                    patch_boundaries_y = [
                        y * (patch_size[1] - patch_offset[1]),
                        y * (patch_size[1] - patch_offset[1]) + patch_size[1],
                    ]
                    patch_boundaries_z = [
                        z * (patch_size[2] - patch_offset[2]),
                        z * (patch_size[2] - patch_offset[2]) + patch_size[2],
                    ]

                    if patch_boundaries_x[1] >= data.shape[1]:
                        diff = abs(data.shape[1] - patch_boundaries_x[1])
                        new_patch_boundaries_x = [patch_boundaries_x[0] - diff, patch_boundaries_x[1] - diff]
                        if new_patch_boundaries_x[0] < 0:
                            continue
                        patch_boundaries_x = new_patch_boundaries_x

                    if patch_boundaries_y[1] >= data.shape[2]:
                        diff = abs(data.shape[2] - patch_boundaries_y[1])
                        new_patch_boundaries_y = [patch_boundaries_y[0] - diff, patch_boundaries_y[1] - diff]
                        if new_patch_boundaries_y[0] < 0:
                            continue
                        patch_boundaries_y = new_patch_boundaries_y

                    if patch_boundaries_z[1] >= data.shape[3]:
                        diff = abs(data.shape[3] - patch_boundaries_z[1])
                        new_patch_boundaries_z = [patch_boundaries_z[0] - diff, patch_boundaries_z[1] - diff]
                        if new_patch_boundaries_z[0] < 0:
                            continue
                        patch_boundaries_z = new_patch_boundaries_z
                    all_patch_boundaries.append([patch_boundaries_x, patch_boundaries_y, patch_boundaries_z])
        for bs_ind in tqdm(range(ceil(len(all_patch_boundaries)/batch_size))):
            batch_inputs = []
            patch_boundaries = all_patch_boundaries[bs_ind * batch_size: min(len(all_patch_boundaries), (bs_ind+1) * batch_size)]
            for pb in patch_boundaries:
                patch_boundaries_x = pb[0]
                patch_boundaries_y = pb[1]
                patch_boundaries_z = pb[2]
                batch_inputs.append(data[
                                        0,
                                        patch_boundaries_x[0]: patch_boundaries_x[1],
                                        patch_boundaries_y[0]: patch_boundaries_y[1],
                                        patch_boundaries_z[0]: patch_boundaries_z[1],
                                        :,
                                    ])
            model_input = np.stack(batch_inputs, axis=0)

            if parameters.preprocessing_channels_order == "channels_first":
                model_input = np.transpose(model_input, axes=(0, 4, 1, 2, 3))
            if parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_first":
                model_input = np.transpose(model_input, axes=(0, 1, 4, 2, 3))
            elif parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_last":
                model_input = np.transpose(model_input, axes=(0, 3, 1, 2, 4))
            # model_input = np.expand_dims(patch, axis=0)
            patch_pred = model.run(None, {"input": model_input})
            # @TODO. Have to test with a non deep supervision model with ONNX, to do array indexing always
            # if deep_supervision or parameters.training_backend == "Torch":
            patch_pred = patch_pred[0]

            if parameters.preprocessing_channels_order == "channels_first":
                patch_pred = np.transpose(patch_pred, axes=(0, 2, 3, 4, 1))
            if parameters.swap_training_input:
                patch_pred = np.transpose(patch_pred, axes=(0, 2, 3, 1, 4))

            # In case of overlapping inference, taking the maximum probabilities overall.
            for pbi, pb in enumerate(patch_boundaries):
                patch_boundaries_x = pb[0]
                patch_boundaries_y = pb[1]
                patch_boundaries_z = pb[2]
                final_result[
                    patch_boundaries_x[0]: patch_boundaries_x[1],
                    patch_boundaries_y[0]: patch_boundaries_y[1],
                    patch_boundaries_z[0]: patch_boundaries_z[1],
                    :,
                ] = np.maximum(patch_pred[pbi],
                    final_result[
                        patch_boundaries_x[0]: patch_boundaries_x[1],
                        patch_boundaries_y[0]: patch_boundaries_y[1],
                        patch_boundaries_z[0]: patch_boundaries_z[1],
                        :,
                    ],
                )

        final_result = final_result[
            extra_dims[0] : final_result.shape[0] - extra_dims[1],
            extra_dims[2] : final_result.shape[1] - extra_dims[3],
            extra_dims[4] : final_result.shape[2] - extra_dims[5],
            :,
        ]

        # For PyTorch-trained models, the final activation layer is often not bundled with the model
        if not parameters.training_activation_layer_included:
            from ..Utils.volume_utilities import final_activation

            final_result = final_activation(final_result, act_type=parameters.training_activation_layer_type)

    except Exception as e:
        logging.error(
            f"Following error collected during model inference (patch mode): \n {e}\n{traceback.format_exc()}"
        )
        raise ValueError("Segmentation inference (patch mode) could not fully proceed.")
    return final_result
