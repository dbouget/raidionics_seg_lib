import logging
import traceback
import numpy as np
from tqdm import tqdm
import onnxruntime as rt
from typing import List
from math import ceil
from copy import deepcopy
from ..Inference.data_augmentation import *
from ..Utils.volume_utilities import padding_for_inference, padding_for_inference_both_ends,\
    padding_for_inference_both_ends_patchwise
from ..Utils.configuration_parser import ConfigResources


def run_predictions(data: np.ndarray, models_path: List[str], parameters: ConfigResources) -> np.ndarray:
    """
    Performs inference using the specified model and TensorFlow as inference engine.

    Parameters
    ----------
    data : np.ndarray
        Pre-processed patient MRI, ready to be used by the inference engine.
    models_path : List[str]
        Filepath where the trained models are stored.
    parameters :  :obj:`ConfigResources`
        Loaded configuration specifying runtime parameters.
    Returns
    -------
    np.ndarray
        Predictions generated by the inference process.
    """
    providers = ['CPUExecutionProvider']
    if parameters.gpu_id != "-1":
        providers = ['CUDAExecutionProvider']
    model_outputs = []

    before_ensemble_results = []

    logging.debug("Predicting...")
    for f, mpf in enumerate(models_path):
        logging.debug("Loading trained model for fold {}".format(f))
        model = rt.InferenceSession(mpf, providers=providers)

        if parameters.new_axial_size and len(parameters.new_axial_size) == 3:
            final_result = __run_predictions_whole(data=data, model=model, parameters=parameters,
                                                   deep_supervision=parameters.training_deep_supervision)
        elif parameters.new_axial_size and len(parameters.new_axial_size) == 2:
            final_result = __run_predictions_slabbed(data=data, model=model, model_outputs=model_outputs,
                                                     parameters=parameters,
                                                     deep_supervision=parameters.training_deep_supervision)
        else:
            final_result = __run_predictions_patch(data=data, model=model, parameters=parameters,
                                                   deep_supervision=parameters.training_deep_supervision)

        if parameters.predictions_test_time_augmentation_iterations > 0:
            logging.debug("Running {} test time augmentation".format(parameters.predictions_test_time_augmentation_iterations))
            augmented_results = np.zeros(final_result.shape + (parameters.predictions_test_time_augmentation_iterations + 1,),
                                         dtype=final_result.dtype)
            augmented_results[..., 0] = final_result
            for i in tqdm(range(parameters.predictions_test_time_augmentation_iterations)):
                aug_list = generate_augmentations(modality=parameters.imaging_modality)
                data_aug = run_augmentations(aug_list, data, "forward")
                aug_result = None
                if parameters.new_axial_size and len(parameters.new_axial_size) == 3:
                    aug_result = __run_predictions_whole(data=data_aug, model=model, parameters=parameters,
                                                           deep_supervision=parameters.training_deep_supervision)
                elif parameters.new_axial_size and len(parameters.new_axial_size) == 2:
                    aug_result = __run_predictions_slabbed(data=data_aug, model=model, model_outputs=model_outputs,
                                                             parameters=parameters,
                                                             deep_supervision=parameters.training_deep_supervision)
                else:
                    aug_result = __run_predictions_patch(data=data_aug, model=model, parameters=parameters,
                                                           deep_supervision=parameters.training_deep_supervision)
                augmented_results[..., i + 1] = np.clip(run_augmentations(aug_list, aug_result, "inverse"),
                                                        a_min=0., a_max=1.)
            # Fusing all test time augmentation results with the main results
            if parameters.predictions_test_time_augmentation_fusion_mode == "maximum":
                final_result = np.amax(augmented_results, axis=-1).astype('float32')
            elif parameters.predictions_test_time_augmentation_fusion_mode == "average":
                final_result = np.average(augmented_results, axis=-1).astype('float32')
        before_ensemble_results.append(final_result)
        del model
    if not parameters.predictions_folds_ensembling:
        return before_ensemble_results[0]
    else:
        ens_result = None
        if parameters.predictions_ensembling_strategy == "maximum":
            ens_result = np.amax(np.stack(before_ensemble_results, axis=-1), axis=-1).astype('float32')
        elif parameters.predictions_ensembling_strategy == "average":
            ens_result = np.average(np.stack(before_ensemble_results, axis=-1), axis=-1).astype('float32')
        return ens_result


def __run_predictions_whole(data: np.ndarray, model, parameters: ConfigResources,
                            deep_supervision: bool = False) -> np.ndarray:
    """
    Performs inference using the specified model using the whole input at once.

    Parameters
    ----------
    data : np.ndarray
        Pre-processed patient MRI, ready to be used by the inference engine.
    model : obj
        Loaded ONNX model.
    parameters: ConfigResources
        Configuration parameters regarding model training or user choices.
    deep_supervision : bool
        Boolean flag to indicate if deep supervision is used in the model.
    Returns
    -------
    np.ndarray
        Predictions generated by the inference process.
    """
    try:
        logging.debug("Starting inference in full volume mode.")
        if parameters.preprocessing_channels_order == "channels_first":
            data = np.transpose(data, axes=(0, 4, 1, 2, 3))
        if parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_first":
            data = np.transpose(data, axes=(0, 1, 4, 2, 3))
        elif parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_last":
            data = np.transpose(data, axes=(0, 3, 1, 2, 4))

        predictions = model.run(None, {"input": data})
        if deep_supervision or parameters.training_backend == "Torch":
            predictions = predictions[0]

        if parameters.preprocessing_channels_order == "channels_first":
            predictions = np.transpose(predictions, axes=(0, 2, 3, 4, 1))
        if parameters.swap_training_input:
            predictions = np.transpose(predictions, axes=(0, 2, 3, 1, 4))

        # For PyTorch-trained models, the final activation layer is often not bundled with the model
        if not parameters.training_activation_layer_included:
            from ..Utils.volume_utilities import final_activation
            predictions = final_activation(predictions, act_type=parameters.training_activation_layer_type)

    except Exception as e:
        logging.error("Following error collected during model inference (whole mode): \n {}".format(traceback.format_exc()))
        raise ValueError("Segmentation inference (whole mode) could not fully proceed.")

    # The batch size dimension can be removed at this point.
    return predictions[0]

def __run_predictions_slabbed(data: np.ndarray, model, model_outputs: List[str], parameters: ConfigResources,
                              deep_supervision: bool = False) -> np.ndarray:
    """
    @TODO. Slab-wise inference working for axial-based slabbing, not tested for the other use-cases.
    @TODO. Also not tested for PyTorch but will most likely never be a use-case now that the patch-wise method is stable.
    """
    try:
        logging.debug("Starting inference in slab-wise mode.")
        slicing_plane = parameters.slicing_plane
        slab_size = parameters.training_slab_size
        new_axial_size = parameters.new_axial_size
        if parameters.swap_training_input:
            tmp = deepcopy(new_axial_size)
            new_axial_size[0] = tmp[1]
            new_axial_size[1] = tmp[0]

        upper_boundary = data.shape[3]
        if slicing_plane == 'sagittal':
            upper_boundary = data.shape[1]
        elif slicing_plane == 'coronal':
            upper_boundary = data.shape[2]

        # Placeholder for the final predictions -- the actual probabilities
        final_result = np.zeros(data.shape[1: -1] + (parameters.training_nb_classes,))
        count = 0

        if parameters.predictions_non_overlapping:
            data, pad_value = padding_for_inference(data=data, slab_size=slab_size, slicing_plane=slicing_plane)
            scale = ceil(upper_boundary / slab_size)
            unpad = False
            for chunk in range(scale):
                if chunk == scale-1 and pad_value != 0:
                    unpad = True

                if slicing_plane == 'axial':
                    slab_CT = data[:, :, :, int(chunk * slab_size):int((chunk + 1) * slab_size), :]
                elif slicing_plane == 'sagittal':
                    tmp = data[:, int(chunk * slab_size):int((chunk + 1) * slab_size), :, :, :]
                    slab_CT = tmp.transpose((0, 2, 3, 1, 4))
                elif slicing_plane == 'coronal':
                    tmp = data[:, :, int(chunk * slab_size):int((chunk + 1) * slab_size), :, :]
                    slab_CT = tmp.transpose((0, 1, 3, 2, 4))

                # slab_CT = np.expand_dims(np.expand_dims(slab_CT, axis=0), axis=-1)
                if parameters.fix_orientation:
                    slab_CT = np.transpose(slab_CT, axes=(0, 3, 1, 2, 4))
                slab_CT_pred = model.run(model_outputs, {"input": slab_CT})

                # When running inference with ONNX, the outputs are packed into a list (even if one output only)
                slab_CT_pred = slab_CT_pred[0]

                if deep_supervision:
                    slab_CT_pred = slab_CT_pred[0]
                if parameters.fix_orientation:
                    slab_CT_pred = np.transpose(slab_CT_pred, axes=(0, 2, 3, 1, 4))

                if not unpad:
                    for c in range(0, slab_CT_pred.shape[-1]):
                        if slicing_plane == 'axial':
                            final_result[:, :, int(chunk * slab_size):int((chunk + 1) * slab_size), c] = \
                                slab_CT_pred[0][:, :, :slab_size, c]
                        elif slicing_plane == 'sagittal':
                            final_result[int(chunk * slab_size):int((chunk + 1) * slab_size), :, :, c] = \
                                slab_CT_pred[0][:, :, :slab_size, c].transpose((2, 0, 1))
                        elif slicing_plane == 'coronal':
                            final_result[:, int(chunk * slab_size):int((chunk + 1) * slab_size), :, c] = \
                                slab_CT_pred[0][:, :, :slab_size, c].transpose((0, 2, 1))
                else:
                    for c in range(0, slab_CT_pred.shape[-1]):
                        if slicing_plane == 'axial':
                            final_result[:, :, int(chunk * slab_size):, c] = \
                                slab_CT_pred[0][:, :, :slab_size-pad_value, c]
                        elif slicing_plane == 'sagittal':
                            final_result[int(chunk * slab_size):, :, :, c] = \
                                slab_CT_pred[0][:, :, :slab_size-pad_value, c].transpose((2, 0, 1))
                        elif slicing_plane == 'coronal':
                            final_result[:, int(chunk * slab_size):, :, c] = \
                                slab_CT_pred[0][:, :, :slab_size-pad_value, c].transpose((0, 2, 1))

                print(count)
                count = count + 1
        else:
            if slab_size == 1:
                for slice in range(0, data.shape[2]):
                    slab_CT = data[:, :, slice, 0]
                    if np.sum(slab_CT > 0.1) == 0:
                        continue
                    slab_CT_pred = model.run(model_outputs, {"input": np.reshape(slab_CT, (1, new_axial_size[0],
                                                                                           new_axial_size[1], 1))})
                    if deep_supervision:
                        slab_CT_pred = slab_CT_pred[0]
                    for c in range(0, slab_CT_pred.shape[-1]):
                        final_result[:, :, slice, c] = slab_CT_pred[:, :, c]
            else:
                #@TODO. Should pad also to make sure all the initial slices have a prediction
                data = padding_for_inference_both_ends(data=data, slab_size=slab_size, slicing_plane=slicing_plane)
                half_slab_size = int(slab_size / 2)
                #for slice in range(half_slab_size, upper_boundary - half_slab_size):
                for slice in range(half_slab_size, upper_boundary):
                    if slicing_plane == 'axial':
                        slab_CT = data[:, :, slice - half_slab_size:slice + half_slab_size, 0]
                    elif slicing_plane == 'sagittal':
                        slab_CT = data[slice - half_slab_size:slice + half_slab_size, :, :, 0]
                        slab_CT = slab_CT.transpose((1, 2, 0))
                    elif slicing_plane == 'coronal':
                        slab_CT = data[:, slice - half_slab_size:slice + half_slab_size, :, 0]
                        slab_CT = slab_CT.transpose((0, 2, 1))

                    slab_CT = np.reshape(slab_CT, (1, new_axial_size[0], new_axial_size[1], slab_size, 1))
                    if np.sum(slab_CT > 0.1) == 0:
                        continue

                    if parameters.fix_orientation:
                        slab_CT = np.transpose(slab_CT, axes=(0, 3, 1, 2, 4))
                    slab_CT_pred = model.run(model_outputs, {"input": slab_CT})
                    if deep_supervision:
                        slab_CT_pred = slab_CT_pred[0]
                    if parameters.fix_orientation:
                        slab_CT_pred = np.transpose(slab_CT_pred, axes=(0, 2, 3, 1, 4))

                    for c in range(0, slab_CT_pred.shape[-1]):
                        if slicing_plane == 'axial':
                            #final_result[:, :, slice, c] = slab_CT_pred[0][:, :, half_slab_size, c]
                            final_result[:, :, slice - half_slab_size, c] = slab_CT_pred[0][:, :, half_slab_size, c]
                        elif slicing_plane == 'sagittal':
                            final_result[slice, :, :, c] = slab_CT_pred[0][:, :, half_slab_size, c]
                        elif slicing_plane == 'coronal':
                            final_result[:, slice, :, c] = slab_CT_pred[0][:, :, half_slab_size, c]

                    print(count)
                    count = count + 1
    except Exception as e:
        logging.error(
            "Following error collected during model inference (slab mode): \n {}".format(traceback.format_exc()))
        raise ValueError("Segmentation inference (slab mode) could not fully proceed.")
    return final_result


def __run_predictions_patch(data: np.ndarray, model, parameters: ConfigResources,
                            deep_supervision: bool = False) -> np.ndarray:
    try:
        logging.debug("Starting inference in patch-wise mode.")
        patch_size = parameters.training_patch_size
        patch_offset = parameters.training_patch_offset
        if parameters.predictions_overlapping_ratio is not None:
            patch_offset = [int(parameters.predictions_overlapping_ratio * x) for x in patch_size]

        # Padding in case the patch size is larger that one of the volume dimensions
        data, extra_dims = padding_for_inference_both_ends_patchwise(data, patch_size)

        # Placeholder for the final predictions -- the actual probabilities
        final_result = np.full(data.shape[1: -1] + (parameters.training_nb_classes,), -100.0, dtype=np.float32)

        all_patch_boundaries = []
        for x in range(0, int(np.ceil(data.shape[1] / (patch_size[0] - patch_offset[0])))):
            for y in range(0, int(np.ceil(data.shape[2] / (patch_size[1] - patch_offset[1])))):
                for z in range(0, int(np.ceil(data.shape[3] / (patch_size[2] - patch_offset[2])))):
                    patch_boundaries_x = [x * (patch_size[0] - patch_offset[0]), x * (patch_size[0] - patch_offset[0]) + patch_size[0]]
                    patch_boundaries_y = [y * (patch_size[1] - patch_offset[1]), y * (patch_size[1] - patch_offset[1]) + patch_size[1]]
                    patch_boundaries_z = [z * (patch_size[2] - patch_offset[2]), z * (patch_size[2] - patch_offset[2]) + patch_size[2]]

                    if patch_boundaries_x[1] >= data.shape[1]:
                        diff = abs(data.shape[1] - patch_boundaries_x[1])
                        new_patch_boundaries_x = [patch_boundaries_x[0] - diff, patch_boundaries_x[1] - diff]
                        if new_patch_boundaries_x[0] < 0:
                            continue
                        patch_boundaries_x = new_patch_boundaries_x

                    if patch_boundaries_y[1] >= data.shape[2]:
                        diff = abs(data.shape[2] - patch_boundaries_y[1])
                        new_patch_boundaries_y = [patch_boundaries_y[0] - diff, patch_boundaries_y[1] - diff]
                        if new_patch_boundaries_y[0] < 0:
                            continue
                        patch_boundaries_y = new_patch_boundaries_y

                    if patch_boundaries_z[1] >= data.shape[3]:
                        diff = abs(data.shape[3] - patch_boundaries_z[1])
                        new_patch_boundaries_z = [patch_boundaries_z[0] - diff, patch_boundaries_z[1] - diff]
                        if new_patch_boundaries_z[0] < 0:
                            continue
                        patch_boundaries_z = new_patch_boundaries_z
                    all_patch_boundaries.append([patch_boundaries_x, patch_boundaries_y, patch_boundaries_z])
        for patch_boundaries in tqdm(all_patch_boundaries):
            patch_boundaries_x = patch_boundaries[0]
            patch_boundaries_y = patch_boundaries[1]
            patch_boundaries_z = patch_boundaries[2]
            model_input = data[:, patch_boundaries_x[0]:patch_boundaries_x[1],
                    patch_boundaries_y[0]:patch_boundaries_y[1],
                    patch_boundaries_z[0]:patch_boundaries_z[1], :]
            if parameters.preprocessing_channels_order == "channels_first":
                model_input = np.transpose(model_input, axes=(0, 4, 1, 2, 3))
            if parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_first":
                model_input = np.transpose(model_input, axes=(0, 1, 4, 2, 3))
            elif parameters.swap_training_input and parameters.preprocessing_channels_order == "channels_last":
                model_input = np.transpose(model_input, axes=(0, 3, 1, 2, 4))
            # model_input = np.expand_dims(patch, axis=0)
            patch_pred = model.run(None, {"input": model_input})
            # @TODO. Have to test with a non deep supervision model with ONNX, to do array indexing always
            if deep_supervision or parameters.training_backend == "Torch":
                patch_pred = patch_pred[0]

            if parameters.preprocessing_channels_order == "channels_first":
                patch_pred = np.transpose(patch_pred, axes=(0, 2, 3, 4, 1))
            if parameters.swap_training_input:
                patch_pred = np.transpose(patch_pred, axes=(0, 2, 3, 1, 4))

            # In case of overlapping inference, taking the maximum probabilities overall.
            final_result[patch_boundaries_x[0]:patch_boundaries_x[1],
            patch_boundaries_y[0]:patch_boundaries_y[1],
            patch_boundaries_z[0]:patch_boundaries_z[1], :] = np.maximum(np.squeeze(patch_pred, axis=0),
                                                                         final_result[patch_boundaries_x[0]:patch_boundaries_x[1],
                                                                         patch_boundaries_y[0]:patch_boundaries_y[1],
                                                                         patch_boundaries_z[0]:patch_boundaries_z[1], :])
        final_result = final_result[extra_dims[0]:final_result.shape[0] - extra_dims[1],
                       extra_dims[2]:final_result.shape[1] - extra_dims[3],
                       extra_dims[4]:final_result.shape[2] - extra_dims[5], :]

        # For PyTorch-trained models, the final activation layer is often not bundled with the model
        if not parameters.training_activation_layer_included:
            from ..Utils.volume_utilities import final_activation
            final_result = final_activation(final_result, act_type=parameters.training_activation_layer_type)

    except Exception as e:
        logging.error(
            "Following error collected during model inference (patch mode): \n {}".format(traceback.format_exc()))
        raise ValueError("Segmentation inference (patch mode) could not fully proceed.")
    return final_result
